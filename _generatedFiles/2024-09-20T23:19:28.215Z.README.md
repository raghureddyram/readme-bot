Based on the provided information and the change summary, here's an updated README.md file for the Vision Extract project:

# Vision Extract

Vision Extract is a Django-based project that leverages OpenAI's GPT-4 to parse images of PDFs and extract financial data from statements.

## Prerequisites

- Python 3.10 or higher
- Poetry (for dependency management)
- OpenAI API key

## Setup

1. Clone the repository:
   
   git clone <repository-url>
   cd vision-extract
   

2. Install dependencies using Poetry:
   
   poetry install
   

3. Set up environment variables:
   Create a `.env` file in the project root and add your OpenAI API key:
   
   OPENAI_KEY=your_api_key_here
   

## How to Run

1. Apply database migrations:
   
   poetry run python vision/manage.py migrate
   

2. Start the Django development server:
   
   poetry run python vision/manage.py runserver
   

3. Access the application at `http://localhost:8000`

## Available Endpoints

- `/pdf_viewer/{pdf_name}`: Renders the specified PDF in a webpage.
  Example: `http://localhost:8000/pdf_viewer/sample`
- `/pdf_viewer/process`: Processes all PDFs in the `source_pdfs` directory.
  Example: `http://localhost:8000/pdf_viewer/process`
- `/extractions/sample`: Provides JSON output of the extractions from the sample PDF.
  Example: `http://localhost:8000/extractions/sample`

## How to Test

Run the tests using pytest:


poetry run pytest


## Architecture

The project is structured as a Django application with two main components:

1. `pdf_viewer`: Handles PDF rendering and processing.
2. `extractions`: Manages the extraction of financial data from PDFs.

Key architectural choices:

- Uses OpenAI's GPT-4 for intelligent parsing of PDF contents.
- Implements a page-by-page summarization technique to extract relevant information.
- Utilizes Pydantic for structured data modeling and validation.
- Employs Django's built-in admin interface for easy management.

## Extraction Process

1. PDFs are converted to images.
2. Each image is processed using GPT-4 to summarize its contents.
3. Relevant information is extracted using targeted prompts for holdings and account summaries.
4. Pydantic models are used to structure and validate the extracted data.

## Sample Data Structure

The extracted data is structured as follows:

json
{
  "accounts": {
    "account_number": {
      "account_entity_owner": "Owner Name",
      "portfolio_value": 100000.00,
      "holdings": [
        {
          "holding_name": "Stock A",
          "cost_basis": 5000.00
        },
        {
          "holding_name": "Bond B",
          "cost_basis": 10000.00
        }
      ]
    }
  }
}


## Possible Enhancements

1. Implement user authentication and authorization.
2. Add a database backend to store extracted information persistently.
3. Improve error handling and logging.
4. Implement a user interface for easier interaction with the extraction process.
5. Add support for multiple PDF formats and sources.
6. Implement parallel processing for faster extraction of large PDFs.

## Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

## License

[Specify your license here]